{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: Best Fitness = 6828.164643662153\n",
      "Generation 2: Best Fitness = 6828.164643662153\n",
      "Generation 3: Best Fitness = 6828.164643662153\n",
      "Generation 4: Best Fitness = 6828.164643662153\n",
      "Generation 5: Best Fitness = 6828.164643662153\n",
      "Generation 6: Best Fitness = 6828.164643662153\n",
      "Generation 7: Best Fitness = 6828.164643662153\n",
      "Generation 8: Best Fitness = 6828.164643662153\n",
      "Generation 9: Best Fitness = 6828.164643662153\n",
      "Generation 10: Best Fitness = 6828.164643662153\n",
      "Best Solution:  [0.89040668 0.0858273  0.70171714 0.42529727 0.01559578 0.70170707\n",
      " 0.00751858 0.50395963 0.7386455  0.52880835 0.95663149 0.3614837\n",
      " 0.12352611 0.65897753 0.72885246 0.8553211  0.89151823 0.24109868\n",
      " 0.65944656 0.03441046 0.79934045 0.62143353 0.06843768 0.03837044\n",
      " 0.53348802 0.58148843 0.25611836 0.35704658 0.1837005  0.14306727\n",
      " 0.80801487 0.40019292 0.04718437 0.36709247 0.00312793 0.49868036\n",
      " 0.75898044 0.35463695 0.81386353 0.5235866  0.52126594 0.66061901\n",
      " 0.1782455  0.86372884 0.3905496  0.60937561 0.78134808 0.09619296\n",
      " 0.11062432 0.02494718 0.42933325 0.98549254 0.00397409 0.90555808\n",
      " 0.5304476  0.54538899 0.98942135 0.4305238  0.26976774 0.49928917\n",
      " 0.22750778 0.38279867 0.63410128 0.4967657  0.1444093  0.63536443\n",
      " 0.30414167 0.70435479 0.02635051 0.47010333 0.42003412 0.64549309\n",
      " 0.27233119 0.50397186 0.58832663 0.23988908 0.74461529 0.92261923\n",
      " 0.29681831 0.33654102 0.43402554 0.401165   0.2088114  0.2561831\n",
      " 0.40829937 0.40554379 0.58797667 0.26766565 0.1317103  0.92751252\n",
      " 0.9279904  0.22480414 0.88987003 0.68902404 0.57105819 0.8400929\n",
      " 0.58643019 0.7881606  0.16786301 0.04191512 0.13247172 0.015136\n",
      " 0.51895789 0.07768431 0.27430196 0.08005065 0.79595679 0.96480797\n",
      " 0.20187186 0.53704661 0.69122385 0.43651813 0.7245647  0.3340749\n",
      " 0.73763091 0.35683462 0.3745968  0.0299387  0.66987475 0.96995217\n",
      " 0.45999983 0.13510774 0.03502709 0.37880404 0.69390473 0.99127331\n",
      " 0.53336279 0.79801256 0.97963107 0.08718856 0.58821986 0.58388087\n",
      " 0.06865981 0.97646043 0.84700821 0.26260059 0.32419662 0.66001172\n",
      " 0.38748644 0.62323604 0.31138419 0.42301879 0.78938335 0.08070449\n",
      " 0.75460618 0.92736819 0.22634761 0.38664599 0.32151744 0.46487294\n",
      " 0.92437902 0.74237445 0.25198391 0.65188647 0.56354616 0.0608426\n",
      " 0.19699112 0.79169893 0.77790663 0.38596325 0.86196608 0.26610737\n",
      " 0.09334369 0.22658827 0.42524726 0.89244085 0.7043001  0.02545599\n",
      " 0.64853676 0.48155426 0.76248705 0.92439359 0.21067513 0.84350467\n",
      " 0.50865865 0.32543775 0.94666235 0.38402555 0.26043138 0.49083731\n",
      " 0.96035784 0.88043104 0.89251132 0.27083493 0.39567184 0.59308606\n",
      " 0.76390272 0.51740686 0.36854381 0.11332059 0.73635625 0.98940797\n",
      " 0.81828751 0.85993556 0.5301626  0.93519841 0.77215472 0.55468524\n",
      " 0.28728781 0.81476147 0.48055997 0.89400552 0.9612461  0.05529296\n",
      " 0.9018472  0.23500351 0.07665657 0.85423615 0.13942895 0.98657503\n",
      " 0.67478637 0.0976231  0.91491096 0.8865592  0.504743   0.75164659\n",
      " 0.15397061 0.5582889  0.68337316 0.5638103  0.12277549 0.2447617\n",
      " 0.99095862 0.98846151 0.35798263 0.79410592 0.5816818  0.04646834\n",
      " 0.7011593  0.68905143 0.43694158 0.79303061 0.1750423  0.29800249\n",
      " 0.11631133 0.40280633 0.59465821 0.56146927 0.1548273  0.30042571\n",
      " 0.95621881 0.84025138 0.44026418 0.47092828 0.74271733 0.72352241\n",
      " 0.46133282 0.99925537 0.67358467 0.43262142 0.80507793 0.49469198\n",
      " 0.218105   0.78801043 0.82096387 0.12504427 0.6932396  0.81281852\n",
      " 0.33522837 0.45118558 0.37302634 0.51980621 0.49249819 0.9633987\n",
      " 0.60998398 0.12883932 0.79527016 0.78573835 0.39007122 0.90131609\n",
      " 0.92592474 0.19337375 0.73858363 0.08921347 0.49827073 0.9075399\n",
      " 0.28387649 0.37835495 0.07638999 0.71840282 0.10369851 0.76964023\n",
      " 0.11551323 0.98148729 0.06145525 0.35556177 0.9205057  0.37825718\n",
      " 0.14138654 0.94924804 0.03580605 0.53328804 0.76638827 0.72232253\n",
      " 0.12043785 0.80788141 0.36588753 0.46565874 0.06190175 0.96134151\n",
      " 0.74349237 0.17007818 0.04135923 0.91912648 0.35334926 0.91209147\n",
      " 0.52426985 0.39908628 0.92815025 0.28063022 0.77102243 0.86879668\n",
      " 0.61499621 0.84331497 0.00907758 0.32512266 0.17522969 0.80919903\n",
      " 0.14970787 0.09774529 0.45079867 0.21123859 0.84715204 0.29735274\n",
      " 0.0548506  0.27081106 0.9123544  0.55558541 0.09763434 0.62347175\n",
      " 0.68000363 0.71988661 0.82729098 0.8921139  0.628086   0.89724183\n",
      " 0.17356892 0.56489611 0.84777306 0.72030776 0.14677642 0.35398889\n",
      " 0.98940996 0.2403577  0.36756316 0.62706168 0.9216764  0.42646784\n",
      " 0.7743038  0.2861736  0.94224717 0.73045939 0.41107246 0.69987792\n",
      " 0.66696963 0.98499677 0.09028035 0.33378326 0.49170332 0.19215622\n",
      " 0.63384879 0.75416206 0.47389525 0.1909181  0.87481527 0.26888185\n",
      " 0.0659581  0.27381714 0.93565442 0.98947718 0.61003115 0.11695581\n",
      " 0.72354237 0.79169463 0.18845999 0.85834063 0.73275471 0.71182228\n",
      " 0.07465351 0.2716202  0.10675476 0.67720475 0.59276526 0.66845891\n",
      " 0.22332531 0.14392589 0.57769144 0.40974427 0.02921144 0.32972932\n",
      " 0.3485879  0.30095312 0.81773948 0.8187539  0.61962532 0.9415432\n",
      " 0.89850615 0.60607024 0.60253118 0.46360411 0.24888385 0.41390748\n",
      " 0.65932025 0.44319717 0.08150503 0.55507852 0.28302978 0.78881918\n",
      " 0.44651006 0.25650686 0.97290339 0.20090337 0.55347534 0.69470464\n",
      " 0.97045201 0.08120452 0.49585498 0.19823379 0.49330955 0.07519124\n",
      " 0.63928739 0.60637093 0.09719519 0.20550638 0.62106146 0.88012036\n",
      " 0.50651323 0.39866649 0.60682113 0.42073394 0.05406679 0.10170681\n",
      " 0.45032028 0.02274476 0.27131562 0.67757345 0.85133053 0.56317251\n",
      " 0.37550939 0.49547372 0.30793928 0.62906895 0.61001264 0.26699216\n",
      " 0.71042748 0.39648999 0.29966182 0.94248427 0.6295497  0.55975386\n",
      " 0.18515644 0.14912079 0.38592517 0.47173974 0.17843855 0.6675532\n",
      " 0.45597559 0.98094902 0.08964838 0.64025474 0.66634112 0.99435862\n",
      " 0.73854159 0.57112838 0.5693057  0.86684751 0.14753216 0.18036224\n",
      " 0.96066048 0.63804795 0.50613307 0.74854307 0.89750968 0.82783185\n",
      " 0.42073829 0.73410291 0.76839461 0.50095447 0.05891729 0.73077688\n",
      " 0.06107682 0.98259325 0.37977098 0.41477699 0.22797823 0.3398374\n",
      " 0.44475187 0.77586216 0.54968948 0.96654831 0.85371716 0.7317483\n",
      " 0.11360988 0.35758424 0.50033066 0.9471968  0.83182162 0.7764574\n",
      " 0.17896075 0.88932429 0.76900989 0.14682038 0.04001725 0.15792914\n",
      " 0.45068556 0.12611329 0.60361543 0.66397489 0.97456391 0.28367637\n",
      " 0.20471599 0.63212048 0.26132209 0.22663357 0.05846707 0.42719969\n",
      " 0.29930762 0.69126162 0.74940325 0.27729979 0.60921862 0.17031961\n",
      " 0.4599255  0.65406437 0.20928896 0.28009118 0.03198149 0.28979775\n",
      " 0.4410861  0.94440893 0.40013083 0.71054058 0.53498624 0.74151509\n",
      " 0.82865735 0.95233445 0.62991515 0.98280689 0.42024563 0.44723919\n",
      " 0.67344555 0.83321386 0.4465541  0.03153083 0.6013088  0.3903794\n",
      " 0.17418724 0.35563711 0.1910295  0.99120289 0.86398813 0.50657857\n",
      " 0.71982306 0.7595741  0.46840436 0.42746492 0.78984132 0.72412546\n",
      " 0.40412386 0.61059506 0.8278156  0.08797178 0.35371073 0.50353153\n",
      " 0.78822269 0.12839675 0.69069828 0.73984896 0.18984682 0.3000685\n",
      " 0.5183669  0.17048833 0.11770324 0.89314323 0.35372935 0.45482696\n",
      " 0.29147051 0.49164282 0.53107925 0.90354277 0.88710798 0.96068297\n",
      " 0.28491914 0.93678797 0.15229255 0.909176   0.29433201 0.83114727\n",
      " 0.89971215 0.48231285 0.45175801 0.4988904  0.16619028 0.10317877\n",
      " 0.47858728 0.10747069 0.444273   0.12719827 0.5922346  0.30229492\n",
      " 0.00627026 0.01593976 0.82067561 0.9427096  0.68145888 0.05416998\n",
      " 0.54852872 0.88307149 0.26622005 0.26008989 0.1986767  0.82637828\n",
      " 0.32741243 0.52251471 0.39412725 0.97201944 0.37237691 0.37999831\n",
      " 0.18043121 0.83764242 0.38852496 0.13668972 0.6473141  0.71754645\n",
      " 0.9297344  0.02146431 0.24924907 0.29042135 0.9475313  0.53684725\n",
      " 0.04751707 0.29823611 0.93384564 0.52489304 0.72886285 0.2544552\n",
      " 0.42832991 0.09481087 0.8795513  0.18824919 0.99634598 0.73564994\n",
      " 0.83658072 0.59096557 0.88515644 0.95295917 0.31782623 0.75688755\n",
      " 0.72199454 0.72366034 0.62923048 0.45099929 0.61876314 0.91242313\n",
      " 0.59390451 0.54288799 0.87561388 0.86711125 0.34520111 0.76665714\n",
      " 0.53978319 0.99374197 0.61611336 0.47486984 0.2471419  0.23395019\n",
      " 0.80894766 0.28274191 0.17527468 0.44761495 0.54834703 0.84724284\n",
      " 0.01808521 0.77723643 0.90560877 0.77213573 0.18387641 0.20306007\n",
      " 0.73722096 0.1567662  0.52106701 0.82988138 0.08755766 0.66430793\n",
      " 0.74193101 0.65004908 0.3354091  0.78289153 0.43434831 0.42911069\n",
      " 0.8602465  0.57008993 0.28209517 0.91075694 0.61803172 0.05152002\n",
      " 0.57013364 0.0353159  0.14116235 0.09484886 0.08492331 0.63741281\n",
      " 0.17301921 0.25406212 0.85195454 0.28271939 0.17702127 0.17800751\n",
      " 0.95140111 0.98357982 0.42098195 0.80478015 0.21012178 0.40759109\n",
      " 0.05657072 0.04737832 0.54788349 0.450179   0.45525606 0.97298674\n",
      " 0.40735671 0.22691436 0.70740309 0.38486932 0.262396   0.54147182\n",
      " 0.44548372 0.04495682 0.68884616 0.53345173 0.62511071 0.83283524\n",
      " 0.54143357 0.94056851 0.8754043  0.31328176 0.89463133 0.35605384\n",
      " 0.88696315 0.20479963 0.82469316 0.3668151  0.35206647 0.95048441\n",
      " 0.75299155 0.74733779 0.8085616  0.17985216 0.3463535  0.68475436\n",
      " 0.59205139 0.11224573 0.45932768 0.70840062 0.46438088 0.39375884\n",
      " 0.50769478 0.38534623 0.536542   0.07037896 0.57211309 0.37545484\n",
      " 0.982322   0.93398954 0.19025301 0.97633473 0.99908665 0.3967881\n",
      " 0.82453277 0.87944871 0.927353   0.25292658 0.93825077 0.6957649\n",
      " 0.47739496 0.72394057 0.31518715 0.59378307 0.39032873 0.02502361\n",
      " 0.97121591 0.24397277 0.66253658 0.86699966 0.13794083 0.21369432\n",
      " 0.05614703 0.67743632 0.97431927 0.98974598 0.00348283 0.6161053\n",
      " 0.51046591 0.92925645 0.28944476 0.39457951 0.82473087 0.57789823\n",
      " 0.37933715 0.03400585 0.62868506 0.64254799 0.50907965 0.29005569\n",
      " 0.2438225  0.26856365 0.69883094 0.33548026 0.02022824 0.16337511\n",
      " 0.32331163 0.98687327 0.45859224 0.45054542 0.40971864 0.75916398\n",
      " 0.13059935 0.36809265 0.07755285 0.26447866 0.09720779 0.94237108\n",
      " 0.21530037 0.78644391 0.35829897 0.14607392 0.00421696 0.06505529\n",
      " 0.41054345 0.37473005 0.74235497 0.08250989 0.95830036 0.75795013\n",
      " 0.54842398 0.80040626 0.67529008 0.77276204 0.06368393 0.64713301\n",
      " 0.35448035 0.3259463  0.20173382 0.1289081  0.19219576 0.72185574\n",
      " 0.57655893 0.87590543 0.37410188 0.75818986 0.05623869 0.55202203\n",
      " 0.90136914 0.66284927 0.05416539 0.23239757 0.4676983  0.67256251\n",
      " 0.97434007 0.44251782 0.12163262 0.37769812 0.50456896 0.30754073\n",
      " 0.91813294 0.97859652 0.44548654 0.4519662  0.8502149  0.62772021\n",
      " 0.86335125 0.40238503 0.09455238 0.42503985 0.1794259  0.43032409\n",
      " 0.78565396 0.66311053 0.38488898 0.24148097 0.1987611  0.89287314\n",
      " 0.63962568 0.2289914  0.85036894 0.81325771 0.45693725 0.02585965\n",
      " 0.95182366 0.57861536 0.83265992 0.70674864 0.8291958  0.31028086\n",
      " 0.66596732 0.07850495 0.38513202 0.82486501 0.17165268 0.58894032\n",
      " 0.73921747 0.91808946 0.77378691 0.26663406 0.92841114 0.34656003\n",
      " 0.88916177 0.62381484 0.10947645 0.61443438 0.28386583 0.05158162\n",
      " 0.46519128 0.23256262 0.27724615 0.9731331  0.83039912 0.99363865\n",
      " 0.80129993 0.17119347 0.74342466 0.39279612 0.94328373 0.02543669\n",
      " 0.12568894 0.48273987 0.20370085 0.20163488 0.74908449 0.86230685\n",
      " 0.59867843 0.67779394 0.888075   0.46779622 0.04824375 0.70324757\n",
      " 0.72718386 0.55684168 0.72818813 0.73116368 0.6233821  0.38208597\n",
      " 0.38359184 0.16110756 0.39607409 0.60529651 0.96436556 0.52431225\n",
      " 0.14899335 0.70510542 0.18967338 0.42127304 0.53837717 0.29164567\n",
      " 0.10972605 0.22907774 0.25424259 0.95409118 0.88341306 0.07459707\n",
      " 0.973885   0.39390082 0.23384034 0.45052933 0.28468409 0.02795811\n",
      " 0.6662272  0.2359483  0.18531832 0.1147299  0.48435965 0.26661483\n",
      " 0.80942116 0.70885328 0.4797981  0.99116763 0.39506472 0.30890964\n",
      " 0.50091473 0.07653586 0.05227176 0.04699283 0.32900542 0.22215396\n",
      " 0.13827413 0.58739542 0.38701433 0.74817654 0.0873118  0.89022983\n",
      " 0.64112128 0.02889169 0.64452169 0.21759133 0.9303434  0.95231357\n",
      " 0.54970281 0.9435641  0.78383548 0.43587328]\n",
      "Best Solution Fitness:  6828.164643662153\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"src/\")\n",
    "import pygad\n",
    "from calcu_lambda import compute_lambda\n",
    "from functools import partial\n",
    "from soft_thres import soft_thres_l1\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "# Define the objective function\n",
    "def fit_func(W, v, lambda_, ga_instance, solution, solution_idx):\n",
    "    ###!! Calculating lambda, this method is only valid when no PPI is considered\n",
    "\n",
    "    # mean_v = np.mean(v)\n",
    "    # sd_v = np.std(v)\n",
    "\n",
    "    # # for W, calculate row mean\n",
    "    # mean_W = np.mean(W)\n",
    "    # sd_W = np.std(W)\n",
    "    # M_v = mean_v / sd_v\n",
    "    # M_w = mean_W / sd_W\n",
    "    # lambda_ = M_w / (M_v + M_w)\n",
    "    # print(f\"Lambda: {lambda_}\")\n",
    "\n",
    "    x = np.array(solution)\n",
    "\n",
    "    term1 = lambda_ * np.dot(x.T, np.dot(W, x))\n",
    "    term2 = (1 - lambda_) * np.dot(v.T, x)\n",
    "    loss = term1 + term2\n",
    "    return loss\n",
    "\n",
    "# def on_mutation(ga_instance):\n",
    "#     for sol_idx, solution in enumerate(ga_instance.population):\n",
    "#         # Ensure non-negativity\n",
    "#         solution = np.maximum(solution, 0)\n",
    "#         solution = soft_thres_l1(solution)\n",
    "#         # solution = solution / np.sum(solution)\n",
    "#         ga_instance.population[sol_idx] = solution\n",
    "#         print(solution.sum(), solution.max(), 'mutation')\n",
    "\n",
    "def on_mutation(ga_instance, offspring):\n",
    "    for sol_idx in range(offspring.shape[0]):\n",
    "        # Ensure non-negativity\n",
    "        offspring[sol_idx] = np.maximum(offspring[sol_idx], 0)\n",
    "        # Apply soft thresholding for L1 regularization\n",
    "        offspring[sol_idx] = soft_thres_l1(offspring[sol_idx])\n",
    "    return offspring\n",
    "\n",
    "def on_generation(ga_instance):\n",
    "    for sol_idx, solution in enumerate(ga_instance.population):\n",
    "        # Ensure non-negativity\n",
    "        # solution = np.maximum(solution, 0)\n",
    "        # # solution = solution / np.sum(solution)\n",
    "        # ga_instance.population[sol_idx] = solution\n",
    "        solution = soft_thres_l1(solution)\n",
    "    print(\n",
    "        f\"Generation {ga_instance.generations_completed}: Best Fitness = {ga_instance.best_solution()[1]}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def create_normalized_population(sol_per_pop, num_genes):\n",
    "    population = np.random.uniform(\n",
    "        low=0.0, high=1.0, size=(sol_per_pop, num_genes)\n",
    "    )\n",
    "    # population /= population.sum(axis=1, keepdims=True)\n",
    "    return population\n",
    "\n",
    "\n",
    "def arithmetic_crossover(parents, offspring_size, ga_instance):\n",
    "    offspring = np.empty(offspring_size)\n",
    "    for k in range(offspring_size[0]):\n",
    "        parent1_idx = k % parents.shape[0]\n",
    "        parent2_idx = (k + 1) % parents.shape[0]\n",
    "        alpha = np.random.uniform(0, 1, size=offspring_size[1])\n",
    "        offspring[k, :] = alpha * parents[parent1_idx, :] + (1 - alpha) * parents[parent2_idx, :]\n",
    "    return offspring\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for idx in range(1, 2):\n",
    "        W = np.load(f\"output/sparse_v_W/W_case{idx}.npy\")\n",
    "        v = np.load(f\"output/sparse_v_W/v_case{idx}.npy\")\n",
    "        lambda_ = compute_lambda(W, v, num_samples=1000)\n",
    "        # print(f\"Lambda: {lambda_}\")\n",
    "        fitness_func = lambda ga_instance, solution, solution_idx: fit_func(\n",
    "            W, v, lambda_, ga_instance, solution, solution_idx\n",
    "        )\n",
    "\n",
    "        # GA parameters\n",
    "        num_iterations = 1000  # Set the number of iterations # 60000\n",
    "        num_generations = (\n",
    "            num_iterations  # Assuming one generation per iteration\n",
    "        )\n",
    "        num_parents_mating = 50\n",
    "        sol_per_pop = 100\n",
    "        num_genes = len(W)  # Ensure num_genes matches the dimension of W and v\n",
    "        mutation_rate = 1 / (num_genes + 1)  # Set mutation rate\n",
    "        crossover_rate = 0.5  # Set crossover rate\n",
    "        initial_population = create_normalized_population(\n",
    "            sol_per_pop, num_genes\n",
    "        )\n",
    "\n",
    "        # Creating an instance of the GA\n",
    "        ga_instance = pygad.GA(\n",
    "            num_generations=num_generations,\n",
    "            num_parents_mating=num_parents_mating,\n",
    "            fitness_func=fitness_func,\n",
    "            sol_per_pop=sol_per_pop,\n",
    "            num_genes=num_genes,\n",
    "            mutation_type=\"random\",\n",
    "            mutation_percent_genes=20,  # pygad uses percentage\n",
    "            on_mutation=on_mutation,\n",
    "            crossover_type=arithmetic_crossover,  # Experiment with different crossover methods\n",
    "            crossover_probability=crossover_rate,  # Set crossover rate\n",
    "            on_generation=on_generation,\n",
    "            stop_criteria=[\n",
    "                \"saturate_10\"\n",
    "            ],  # Stop if no improvement for 100 generations\n",
    "            keep_parents=1,\n",
    "            initial_population=initial_population,\n",
    "        )\n",
    "        # Running the GA\n",
    "        ga_instance.run()\n",
    "\n",
    "        # Best solution\n",
    "        solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "        print(\"Best Solution: \", solution)\n",
    "        print(\"Best Solution Fitness: \", solution_fitness)\n",
    "\n",
    "        # Save the best solution\n",
    "        # np.save(f\"output/best_solution_case{idx}.npy\", solution)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(solution.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft-thresholded Solution:  1.0\n",
      "Non-zero elements:  [  0   1   2   3   4   5   7   8   9  10  11  12  13  14  16  17  18  19\n",
      "  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  51  52  53  54  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  86  87  88  89  90  91  92  93\n",
      "  94  95  96  97  98  99 100 101 103 104 105 106 107 108 109 110 111 112\n",
      " 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 144 145 146 147 148 149\n",
      " 150 151 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168\n",
      " 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187\n",
      " 188 189 190 191 192 193 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 211 213 214 215 216 217 218 219 220 222 223 224 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 253 254 255 257 258 259 260 261 262 263 264 265\n",
      " 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283\n",
      " 284 285 286 287 288 289 290 291 292 293 295 296 297 298 299 300 301 303\n",
      " 304 305 306 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322\n",
      " 323 324 325 327 328 329 331 332 333 335 336 337 338 340 341 342 343 344\n",
      " 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362\n",
      " 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380\n",
      " 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398\n",
      " 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416\n",
      " 417 419 420 421 422 423 424 425 426 427 428 429 430 432 433 434 435 436\n",
      " 437 438 439 440 441 443 444 445 446 447 448 449 450 451 452 453 454 455\n",
      " 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473\n",
      " 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 491 492\n",
      " 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510\n",
      " 511 512 513 514 515 516 517 518 519 520 521 522 524 525 526 527 528 530\n",
      " 531 532 533 534 536 537 539 541 542 543 544 545 546 547 548 549 550 551\n",
      " 552 553 554 556 557 558 560 561 562 563 564 565 566 567 568 569 570 571\n",
      " 572 573 574 575 576 577 578 579 580 581 582 583 585 586 587 588 589 590\n",
      " 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 609\n",
      " 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627\n",
      " 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645\n",
      " 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663\n",
      " 664 665 666 667 670 671 672 674 675 676 677 678 679 680 681 682 683 684\n",
      " 685 686 687 689 690 691 692 693 694 695 696 697 698 700 701 702 703 704\n",
      " 705 706 708 709 710 711 712 713 714 715 717 718 719 720 721 722 723 724\n",
      " 725 726 727 728 730 732 733 734 735 736 737 738 739 740 741 742 743 744\n",
      " 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762\n",
      " 763 764 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781\n",
      " 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799\n",
      " 800 801 802 803 804 805 806 808 809 810 811 812 813 814 815 816 817 819\n",
      " 820 821 822 823 824 825 826 827 828 829 831 832 833 834 835 836 837 838\n",
      " 839 840 841 842 843 844 845 847 848 849 850 851 852 853 854 855 856 857\n",
      " 858 859 860 861 862 863 864 865 866 867 868 869 871 872 873 874 875 876\n",
      " 877 878 879 880 881 882 883 884 885 886 888 889 890 891 892 893 894 895\n",
      " 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913\n",
      " 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931\n",
      " 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949\n",
      " 950 952 953 954 955 956 958 959 960 961 962 964 965 966 967 968 969 970\n",
      " 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988\n",
      " 989 990 991 992 993 994 995 996 997 998 999]\n"
     ]
    }
   ],
   "source": [
    "solution_soft = soft_thres_l1(solution)\n",
    "print(\"Soft-thresholded Solution: \", solution_soft.sum())\n",
    "# print non-zero elements as list\n",
    "print(\"Non-zero elements: \", np.nonzero(solution_soft)[0])\n",
    "indices = np.nonzero(solution_soft)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "947\n"
     ]
    }
   ],
   "source": [
    "print(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94305.56531245612 902.705065424358\n",
      "93240.590645145 579.1497630157643\n",
      "117975.8971528779 897.5093933807915\n",
      "83994.81533151757 578.9871866849234\n"
     ]
    }
   ],
   "source": [
    "for idx in range(1, 5):\n",
    "    W = np.load(f\"output/sparse_v_W/W_case{idx}.npy\")\n",
    "    v = np.load(f\"output/sparse_v_W/v_case{idx}.npy\")\n",
    "\n",
    "    print(W.sum(), v.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: Best Fitness = 5952.138115521779\n",
      "Generation 2: Best Fitness = 6630.847684066706\n",
      "Generation 3: Best Fitness = 7615.634165057199\n",
      "Generation 4: Best Fitness = 7689.028809278906\n",
      "Generation 5: Best Fitness = 8295.278307563693\n",
      "Generation 6: Best Fitness = 9949.885996257235\n",
      "Generation 7: Best Fitness = 11170.969799782999\n",
      "Generation 8: Best Fitness = 11949.87872472393\n",
      "Generation 9: Best Fitness = 13299.682450349908\n",
      "Generation 10: Best Fitness = 14898.237021559504\n",
      "Generation 11: Best Fitness = 15785.57463174141\n",
      "Generation 12: Best Fitness = 18700.673232161786\n",
      "Generation 13: Best Fitness = 19050.044773053876\n",
      "Generation 14: Best Fitness = 20663.95041225535\n",
      "Generation 15: Best Fitness = 22608.11857038621\n",
      "Generation 16: Best Fitness = 26015.54778445916\n",
      "Generation 17: Best Fitness = 26861.043214659992\n",
      "Generation 18: Best Fitness = 28741.560193721987\n",
      "Generation 19: Best Fitness = 30604.616890483612\n",
      "Generation 20: Best Fitness = 33812.36588017229\n",
      "Generation 21: Best Fitness = 34644.21257189043\n",
      "Generation 22: Best Fitness = 38676.488057375704\n",
      "Generation 23: Best Fitness = 40100.87374097172\n",
      "Generation 24: Best Fitness = 41821.626308639774\n",
      "Generation 25: Best Fitness = 43053.83333706396\n",
      "Generation 26: Best Fitness = 45816.6116158015\n",
      "Generation 27: Best Fitness = 48711.13040437059\n",
      "Generation 28: Best Fitness = 50600.08644662119\n",
      "Generation 29: Best Fitness = 52213.66841221064\n",
      "Generation 30: Best Fitness = 54277.4559448396\n",
      "Generation 31: Best Fitness = 56214.63382115607\n",
      "Generation 32: Best Fitness = 58545.92982570347\n",
      "Generation 33: Best Fitness = 61075.32659928396\n",
      "Generation 34: Best Fitness = 66234.66885988726\n",
      "Generation 35: Best Fitness = 68623.25937491267\n",
      "Generation 36: Best Fitness = 69254.68583428896\n",
      "Generation 37: Best Fitness = 72813.22087118818\n",
      "Generation 38: Best Fitness = 73483.72739980982\n",
      "Generation 39: Best Fitness = 76532.72589816008\n",
      "Generation 40: Best Fitness = 78820.58324391152\n",
      "Generation 41: Best Fitness = 82952.73523892928\n",
      "Generation 42: Best Fitness = 84295.1601003844\n",
      "Generation 43: Best Fitness = 86501.23696048885\n",
      "Generation 44: Best Fitness = 90166.55370882321\n",
      "Generation 45: Best Fitness = 91981.26485291113\n",
      "Generation 46: Best Fitness = 94653.46931050054\n",
      "Generation 47: Best Fitness = 99654.26864297272\n",
      "Generation 48: Best Fitness = 101066.83109587048\n",
      "Generation 49: Best Fitness = 104465.53240922614\n",
      "Generation 50: Best Fitness = 105990.24508804441\n",
      "Generation 51: Best Fitness = 108520.44922587837\n",
      "Generation 52: Best Fitness = 111425.09688392362\n",
      "Generation 53: Best Fitness = 116522.88652001534\n",
      "Generation 54: Best Fitness = 121404.98750695544\n",
      "Generation 55: Best Fitness = 123931.76074477713\n",
      "Generation 56: Best Fitness = 127303.54938937038\n",
      "Generation 57: Best Fitness = 132312.24947199723\n",
      "Generation 58: Best Fitness = 135097.66384381655\n",
      "Generation 59: Best Fitness = 135568.24938293218\n",
      "Generation 60: Best Fitness = 140378.39952970715\n",
      "Generation 61: Best Fitness = 146061.78933523255\n",
      "Generation 62: Best Fitness = 148081.32464052443\n",
      "Generation 63: Best Fitness = 151853.4271432619\n",
      "Generation 64: Best Fitness = 156173.58528852253\n",
      "Generation 65: Best Fitness = 155452.72411432522\n",
      "Generation 66: Best Fitness = 159960.04446487833\n",
      "Generation 67: Best Fitness = 160755.00001514563\n",
      "Generation 68: Best Fitness = 165632.1679309423\n",
      "Generation 69: Best Fitness = 168332.83444695934\n",
      "Generation 70: Best Fitness = 171564.9221230674\n",
      "Generation 71: Best Fitness = 175476.00330929828\n",
      "Generation 72: Best Fitness = 181334.9283782858\n",
      "Generation 73: Best Fitness = 185140.46844931066\n",
      "Generation 74: Best Fitness = 187918.71064937246\n",
      "Generation 75: Best Fitness = 189883.2411949052\n",
      "Generation 76: Best Fitness = 192239.67282341825\n",
      "Generation 77: Best Fitness = 196881.66035011367\n",
      "Generation 78: Best Fitness = 199424.8059188513\n",
      "Generation 79: Best Fitness = 205295.54502023378\n",
      "Generation 80: Best Fitness = 209967.54116865364\n",
      "Generation 81: Best Fitness = 215426.55895697157\n",
      "Generation 82: Best Fitness = 217187.74539094092\n",
      "Generation 83: Best Fitness = 223719.57757717546\n",
      "Generation 84: Best Fitness = 229120.24507377582\n",
      "Generation 85: Best Fitness = 232640.29867893405\n",
      "Generation 86: Best Fitness = 234706.75078376583\n",
      "Generation 87: Best Fitness = 238123.2012060815\n",
      "Generation 88: Best Fitness = 244354.25962617027\n",
      "Generation 89: Best Fitness = 247138.55234029487\n",
      "Generation 90: Best Fitness = 250397.7837011641\n",
      "Generation 91: Best Fitness = 254870.87616204564\n",
      "Generation 92: Best Fitness = 256151.35263744128\n",
      "Generation 93: Best Fitness = 263575.8946339181\n",
      "Generation 94: Best Fitness = 268580.2736657718\n",
      "Generation 95: Best Fitness = 271939.888131151\n",
      "Generation 96: Best Fitness = 275360.7631633326\n",
      "Generation 97: Best Fitness = 279316.54781330196\n",
      "Generation 98: Best Fitness = 285276.7788907472\n",
      "Generation 99: Best Fitness = 288166.4023223844\n",
      "Generation 100: Best Fitness = 291411.0376084297\n",
      "Generation 101: Best Fitness = 297871.3263246992\n",
      "Generation 102: Best Fitness = 302214.8044008696\n",
      "Generation 103: Best Fitness = 304309.52669369784\n",
      "Generation 104: Best Fitness = 313194.1443358691\n",
      "Generation 105: Best Fitness = 316012.8566073044\n",
      "Generation 106: Best Fitness = 317874.0890068577\n",
      "Generation 107: Best Fitness = 319008.4095973646\n",
      "Generation 108: Best Fitness = 325421.2583360311\n",
      "Generation 109: Best Fitness = 329180.242260733\n",
      "Generation 110: Best Fitness = 337554.1210980975\n",
      "Generation 111: Best Fitness = 341824.9115213661\n",
      "Generation 112: Best Fitness = 346822.25095757365\n",
      "Generation 113: Best Fitness = 349285.8114369949\n",
      "Generation 114: Best Fitness = 354814.23084916634\n",
      "Generation 115: Best Fitness = 366694.4690961897\n",
      "Generation 116: Best Fitness = 370926.28284613206\n",
      "Generation 117: Best Fitness = 372721.07021471567\n",
      "Generation 118: Best Fitness = 374103.2198526554\n",
      "Generation 119: Best Fitness = 381431.6748677553\n",
      "Generation 120: Best Fitness = 391978.5970588938\n",
      "Generation 121: Best Fitness = 392696.350500784\n",
      "Generation 122: Best Fitness = 395637.88299925794\n",
      "Generation 123: Best Fitness = 401369.4326730441\n",
      "Generation 124: Best Fitness = 408479.4573529148\n",
      "Generation 125: Best Fitness = 413673.15908069076\n",
      "Generation 126: Best Fitness = 423842.8062013769\n",
      "Generation 127: Best Fitness = 428282.19697453035\n",
      "Generation 128: Best Fitness = 437048.06632060814\n",
      "Generation 129: Best Fitness = 442972.4849623436\n",
      "Generation 130: Best Fitness = 446335.9216358505\n",
      "Generation 131: Best Fitness = 452440.74906147405\n",
      "Generation 132: Best Fitness = 454913.72574040276\n",
      "Generation 133: Best Fitness = 464972.5288076856\n",
      "Generation 134: Best Fitness = 465792.9443344589\n",
      "Generation 135: Best Fitness = 472036.29843512544\n",
      "Generation 136: Best Fitness = 476922.3579087448\n",
      "Generation 137: Best Fitness = 476950.43680837675\n",
      "Generation 138: Best Fitness = 489233.4117886118\n",
      "Generation 139: Best Fitness = 493153.7211492807\n",
      "Generation 140: Best Fitness = 496652.507760729\n",
      "Generation 141: Best Fitness = 506755.63745464355\n",
      "Generation 142: Best Fitness = 511257.7156270177\n",
      "Generation 143: Best Fitness = 510889.4202175203\n",
      "Generation 144: Best Fitness = 516531.65847322973\n",
      "Generation 145: Best Fitness = 526460.2315187\n",
      "Generation 146: Best Fitness = 532870.3660096761\n",
      "Generation 147: Best Fitness = 535727.3576420919\n",
      "Generation 148: Best Fitness = 544005.7477982261\n",
      "Generation 149: Best Fitness = 551694.3755889436\n",
      "Generation 150: Best Fitness = 565205.7613620067\n",
      "Generation 151: Best Fitness = 567006.22130461\n",
      "Generation 152: Best Fitness = 576819.9263503617\n",
      "Generation 153: Best Fitness = 585948.731227419\n",
      "Generation 154: Best Fitness = 591820.2986333462\n",
      "Generation 155: Best Fitness = 598404.375852608\n",
      "Generation 156: Best Fitness = 601909.0611982952\n",
      "Generation 157: Best Fitness = 604083.1574699135\n",
      "Generation 158: Best Fitness = 613474.9688651358\n",
      "Generation 159: Best Fitness = 616349.1983323621\n",
      "Generation 160: Best Fitness = 621790.736637961\n",
      "Generation 161: Best Fitness = 625312.0291539335\n",
      "Generation 162: Best Fitness = 630142.8562404783\n",
      "Generation 163: Best Fitness = 637009.0531072856\n",
      "Generation 164: Best Fitness = 643058.2540741801\n",
      "Generation 165: Best Fitness = 644960.0035926419\n",
      "Generation 166: Best Fitness = 651202.3217508699\n",
      "Generation 167: Best Fitness = 660727.8642840717\n",
      "Generation 168: Best Fitness = 665222.3618819624\n",
      "Generation 169: Best Fitness = 671111.2211606628\n",
      "Generation 170: Best Fitness = 674746.1760629403\n",
      "Generation 171: Best Fitness = 694687.4509928046\n",
      "Generation 172: Best Fitness = 699949.6610242951\n",
      "Generation 173: Best Fitness = 703159.6272620101\n",
      "Generation 174: Best Fitness = 707862.5282816908\n",
      "Generation 175: Best Fitness = 714933.3741698955\n",
      "Generation 176: Best Fitness = 720334.2584289986\n",
      "Generation 177: Best Fitness = 729314.9497847495\n",
      "Generation 178: Best Fitness = 733130.9346446389\n",
      "Generation 179: Best Fitness = 745069.4475544955\n",
      "Generation 180: Best Fitness = 745152.5422575811\n",
      "Generation 181: Best Fitness = 754572.2676462617\n",
      "Generation 182: Best Fitness = 758529.2438280138\n",
      "Generation 183: Best Fitness = 770901.4402656149\n",
      "Generation 184: Best Fitness = 780846.541491088\n",
      "Generation 185: Best Fitness = 792873.4605473798\n",
      "Generation 186: Best Fitness = 793197.302348175\n",
      "Generation 187: Best Fitness = 795621.4829093597\n",
      "Generation 188: Best Fitness = 807733.6058534486\n",
      "Generation 189: Best Fitness = 809896.3091451103\n",
      "Generation 190: Best Fitness = 822724.8527474613\n",
      "Generation 191: Best Fitness = 828165.5314707706\n",
      "Generation 192: Best Fitness = 836249.6300354504\n",
      "Generation 193: Best Fitness = 838969.8034390709\n",
      "Generation 194: Best Fitness = 849329.144244144\n",
      "Generation 195: Best Fitness = 853357.9313529595\n",
      "Generation 196: Best Fitness = 865007.8098469006\n",
      "Generation 197: Best Fitness = 867044.8638463926\n",
      "Generation 198: Best Fitness = 869667.6420888514\n",
      "Generation 199: Best Fitness = 879325.3687183266\n",
      "Generation 200: Best Fitness = 900959.5654574416\n",
      "Generation 201: Best Fitness = 900244.496436438\n",
      "Generation 202: Best Fitness = 908551.7509526088\n",
      "Generation 203: Best Fitness = 911653.3132036299\n",
      "Generation 204: Best Fitness = 921253.2032300887\n",
      "Generation 205: Best Fitness = 926365.2803537853\n",
      "Generation 206: Best Fitness = 928506.5399084406\n",
      "Generation 207: Best Fitness = 937195.5561153719\n",
      "Generation 208: Best Fitness = 942922.0643176358\n",
      "Generation 209: Best Fitness = 954237.0641789008\n",
      "Generation 210: Best Fitness = 958879.930864365\n",
      "Generation 211: Best Fitness = 965880.8928911659\n",
      "Generation 212: Best Fitness = 968221.8603963092\n",
      "Generation 213: Best Fitness = 979441.5111565572\n",
      "Generation 214: Best Fitness = 986687.9529756788\n",
      "Generation 215: Best Fitness = 992303.002924719\n",
      "Generation 216: Best Fitness = 994313.2542013521\n",
      "Generation 217: Best Fitness = 997325.9410494011\n",
      "Generation 218: Best Fitness = 1006475.1712512395\n",
      "Generation 219: Best Fitness = 1008548.7433758324\n",
      "Generation 220: Best Fitness = 1020329.6014567347\n",
      "Generation 221: Best Fitness = 1033440.8658324673\n",
      "Generation 222: Best Fitness = 1040172.5833490792\n",
      "Generation 223: Best Fitness = 1051406.632895811\n",
      "Generation 224: Best Fitness = 1058268.7745279255\n",
      "Generation 225: Best Fitness = 1065734.8103975914\n",
      "Generation 226: Best Fitness = 1066718.226035712\n",
      "Generation 227: Best Fitness = 1076121.1441628956\n",
      "Generation 228: Best Fitness = 1086843.9216989547\n",
      "Generation 229: Best Fitness = 1100300.755273083\n",
      "Generation 230: Best Fitness = 1107144.1383884174\n",
      "Generation 231: Best Fitness = 1120297.6805022699\n",
      "Generation 232: Best Fitness = 1125706.3121046429\n",
      "Generation 233: Best Fitness = 1133811.8527850406\n",
      "Generation 234: Best Fitness = 1150698.46545779\n",
      "Generation 235: Best Fitness = 1155750.6178000085\n",
      "Generation 236: Best Fitness = 1165523.865042101\n",
      "Generation 237: Best Fitness = 1176165.285841763\n",
      "Generation 238: Best Fitness = 1178990.4819346017\n",
      "Generation 239: Best Fitness = 1181847.6531721144\n",
      "Generation 240: Best Fitness = 1196014.263807105\n",
      "Generation 241: Best Fitness = 1205618.593996267\n",
      "Generation 242: Best Fitness = 1207621.3503871907\n",
      "Generation 243: Best Fitness = 1214772.9695945573\n",
      "Generation 244: Best Fitness = 1224849.5411589267\n",
      "Generation 245: Best Fitness = 1233727.5928780679\n",
      "Generation 246: Best Fitness = 1231917.3861740492\n",
      "Generation 247: Best Fitness = 1247702.595430168\n",
      "Generation 248: Best Fitness = 1254755.2132311708\n",
      "Generation 249: Best Fitness = 1265741.8886132643\n",
      "Generation 250: Best Fitness = 1268934.5761094685\n",
      "Generation 251: Best Fitness = 1287876.3438809146\n",
      "Generation 252: Best Fitness = 1293181.9485398403\n",
      "Generation 253: Best Fitness = 1301259.2192306735\n",
      "Generation 254: Best Fitness = 1301675.733559353\n",
      "Generation 255: Best Fitness = 1307707.3029040042\n",
      "Generation 256: Best Fitness = 1316016.1288315128\n",
      "Generation 257: Best Fitness = 1328195.3184999349\n",
      "Generation 258: Best Fitness = 1337294.596620358\n",
      "Generation 259: Best Fitness = 1344103.8526594578\n",
      "Generation 260: Best Fitness = 1353646.4808900957\n",
      "Generation 261: Best Fitness = 1364312.8914592105\n",
      "Generation 262: Best Fitness = 1363842.8781372865\n",
      "Generation 263: Best Fitness = 1377689.5832308098\n",
      "Generation 264: Best Fitness = 1390037.7871393843\n",
      "Generation 265: Best Fitness = 1389267.3885420847\n",
      "Generation 266: Best Fitness = 1404076.5818284752\n",
      "Generation 267: Best Fitness = 1412414.4911856735\n",
      "Generation 268: Best Fitness = 1415650.5551166218\n",
      "Generation 269: Best Fitness = 1423842.6351201113\n",
      "Generation 270: Best Fitness = 1436389.816924812\n",
      "Generation 271: Best Fitness = 1446321.188407008\n",
      "Generation 272: Best Fitness = 1449358.6249081346\n",
      "Generation 273: Best Fitness = 1462074.3178663943\n",
      "Generation 274: Best Fitness = 1460950.020361203\n",
      "Generation 275: Best Fitness = 1472746.8637149436\n",
      "Generation 276: Best Fitness = 1481448.89787044\n",
      "Generation 277: Best Fitness = 1495110.0599126806\n",
      "Generation 278: Best Fitness = 1494332.1633107336\n",
      "Generation 279: Best Fitness = 1514362.6451966916\n",
      "Generation 280: Best Fitness = 1513859.4954975895\n",
      "Generation 281: Best Fitness = 1531111.5720390363\n",
      "Generation 282: Best Fitness = 1533007.4278442631\n",
      "Generation 283: Best Fitness = 1537659.7478236188\n",
      "Generation 284: Best Fitness = 1546036.4797523662\n",
      "Generation 285: Best Fitness = 1557222.9242022848\n",
      "Generation 286: Best Fitness = 1561562.0771515404\n",
      "Generation 287: Best Fitness = 1568460.4031291846\n",
      "Generation 288: Best Fitness = 1576060.0652566683\n",
      "Generation 289: Best Fitness = 1592004.9262227681\n",
      "Generation 290: Best Fitness = 1596651.0800499725\n",
      "Generation 291: Best Fitness = 1616942.7711225266\n",
      "Generation 292: Best Fitness = 1623489.0518204444\n",
      "Generation 293: Best Fitness = 1626449.0972856588\n",
      "Generation 294: Best Fitness = 1633418.7305895293\n",
      "Generation 295: Best Fitness = 1639560.5146897857\n",
      "Generation 296: Best Fitness = 1653124.369805341\n",
      "Generation 297: Best Fitness = 1677138.9990922422\n",
      "Generation 298: Best Fitness = 1694246.1498562593\n",
      "Generation 299: Best Fitness = 1705345.2453920022\n",
      "Generation 300: Best Fitness = 1716323.889132197\n",
      "Generation 301: Best Fitness = 1724688.5395910183\n",
      "Generation 302: Best Fitness = 1733444.560672292\n",
      "Generation 303: Best Fitness = 1741350.2379043407\n",
      "Generation 304: Best Fitness = 1753768.5594114065\n",
      "Generation 305: Best Fitness = 1767542.1073964753\n",
      "Generation 306: Best Fitness = 1787924.981329346\n",
      "Generation 307: Best Fitness = 1787511.2118302474\n",
      "Generation 308: Best Fitness = 1798768.7027443429\n",
      "Generation 309: Best Fitness = 1803241.509630398\n",
      "Generation 310: Best Fitness = 1819679.5732430217\n",
      "Generation 311: Best Fitness = 1830274.9529054929\n",
      "Generation 312: Best Fitness = 1837690.5083738896\n",
      "Generation 313: Best Fitness = 1847797.7975750712\n",
      "Generation 314: Best Fitness = 1860791.065020477\n",
      "Generation 315: Best Fitness = 1860959.280864937\n",
      "Generation 316: Best Fitness = 1877446.8286399473\n",
      "Generation 317: Best Fitness = 1907532.7391759006\n",
      "Generation 318: Best Fitness = 1914437.0827452254\n",
      "Generation 319: Best Fitness = 1938413.896392082\n",
      "Generation 320: Best Fitness = 1943041.383391451\n",
      "Generation 321: Best Fitness = 1947129.8129938613\n",
      "Generation 322: Best Fitness = 1949295.9303491006\n",
      "Generation 323: Best Fitness = 1969065.668722615\n",
      "Generation 324: Best Fitness = 1990229.9021035053\n",
      "Generation 325: Best Fitness = 1990560.9047932622\n",
      "Generation 326: Best Fitness = 2010806.857152134\n",
      "Generation 327: Best Fitness = 2024379.9302231509\n",
      "Generation 328: Best Fitness = 2023591.214576479\n",
      "Generation 329: Best Fitness = 2029750.9946776053\n",
      "Generation 330: Best Fitness = 2033859.221266569\n",
      "Generation 331: Best Fitness = 2046867.8689116281\n",
      "Generation 332: Best Fitness = 2048158.76489368\n",
      "Generation 333: Best Fitness = 2064712.2198398768\n",
      "Generation 334: Best Fitness = 2086515.1222905724\n",
      "Generation 335: Best Fitness = 2092071.274258855\n",
      "Generation 336: Best Fitness = 2091412.194214908\n",
      "Generation 337: Best Fitness = 2105887.1728941626\n",
      "Generation 338: Best Fitness = 2103919.716286807\n",
      "Generation 339: Best Fitness = 2121646.385069413\n",
      "Generation 340: Best Fitness = 2130417.5214149454\n",
      "Generation 341: Best Fitness = 2137924.184392791\n",
      "Generation 342: Best Fitness = 2141006.5867921617\n",
      "Generation 343: Best Fitness = 2163879.213617678\n",
      "Generation 344: Best Fitness = 2164773.102083992\n",
      "Generation 345: Best Fitness = 2184058.982740726\n",
      "Generation 346: Best Fitness = 2184311.7105992283\n",
      "Generation 347: Best Fitness = 2190946.5193875358\n",
      "Generation 348: Best Fitness = 2199404.8939878796\n",
      "Generation 349: Best Fitness = 2215819.5110886395\n",
      "Generation 350: Best Fitness = 2228026.6793889552\n",
      "Generation 351: Best Fitness = 2236958.949723773\n",
      "Generation 352: Best Fitness = 2241910.329708757\n",
      "Generation 353: Best Fitness = 2258084.948723749\n",
      "Generation 354: Best Fitness = 2268948.796646427\n",
      "Generation 355: Best Fitness = 2291193.259532418\n",
      "Generation 356: Best Fitness = 2301869.67499678\n",
      "Generation 357: Best Fitness = 2310866.3764691185\n",
      "Generation 358: Best Fitness = 2319934.118938225\n",
      "Generation 359: Best Fitness = 2327781.6724680937\n",
      "Generation 360: Best Fitness = 2336747.239123295\n",
      "Generation 361: Best Fitness = 2344663.373010592\n",
      "Generation 362: Best Fitness = 2359354.078514423\n",
      "Generation 363: Best Fitness = 2365732.208558053\n",
      "Generation 364: Best Fitness = 2391731.415003807\n",
      "Generation 365: Best Fitness = 2392866.069720144\n",
      "Generation 366: Best Fitness = 2411370.847342219\n",
      "Generation 367: Best Fitness = 2419743.056192148\n",
      "Generation 368: Best Fitness = 2424105.049468902\n",
      "Generation 369: Best Fitness = 2432097.897700827\n",
      "Generation 370: Best Fitness = 2446477.8609543396\n",
      "Generation 371: Best Fitness = 2465277.648374045\n",
      "Generation 372: Best Fitness = 2475276.6195647037\n",
      "Generation 373: Best Fitness = 2487709.5287746456\n",
      "Generation 374: Best Fitness = 2489509.6051621884\n",
      "Generation 375: Best Fitness = 2507228.6339834556\n",
      "Generation 376: Best Fitness = 2509302.8840398635\n",
      "Generation 377: Best Fitness = 2533139.036877425\n",
      "Generation 378: Best Fitness = 2545170.817577412\n",
      "Generation 379: Best Fitness = 2546851.149594114\n",
      "Generation 380: Best Fitness = 2561743.3934060684\n",
      "Generation 381: Best Fitness = 2576956.4469415224\n",
      "Generation 382: Best Fitness = 2592668.4062872487\n",
      "Generation 383: Best Fitness = 2602078.753319396\n",
      "Generation 384: Best Fitness = 2604051.995282178\n",
      "Generation 385: Best Fitness = 2624604.3152627666\n",
      "Generation 386: Best Fitness = 2646483.030858761\n",
      "Generation 387: Best Fitness = 2650315.292416872\n",
      "Generation 388: Best Fitness = 2652904.4038529606\n",
      "Generation 389: Best Fitness = 2667387.5901813284\n",
      "Generation 390: Best Fitness = 2676723.3720401246\n",
      "Generation 391: Best Fitness = 2686902.0604638853\n",
      "Generation 392: Best Fitness = 2691620.56281247\n",
      "Generation 393: Best Fitness = 2721545.4549586675\n",
      "Generation 394: Best Fitness = 2728426.6928058136\n",
      "Generation 395: Best Fitness = 2746217.2940750793\n",
      "Generation 396: Best Fitness = 2760707.173902165\n",
      "Generation 397: Best Fitness = 2760185.771041734\n",
      "Generation 398: Best Fitness = 2771462.5325932875\n",
      "Generation 399: Best Fitness = 2781765.4279109826\n",
      "Generation 400: Best Fitness = 2798351.6405066806\n",
      "Generation 401: Best Fitness = 2811081.286744361\n",
      "Generation 402: Best Fitness = 2818569.23587026\n",
      "Generation 403: Best Fitness = 2835941.182576784\n",
      "Generation 404: Best Fitness = 2840976.592475956\n",
      "Generation 405: Best Fitness = 2858097.4961391715\n",
      "Generation 406: Best Fitness = 2869225.7409148994\n",
      "Generation 407: Best Fitness = 2875905.0867552566\n",
      "Generation 408: Best Fitness = 2888602.9991229796\n",
      "Generation 409: Best Fitness = 2903055.5648099002\n",
      "Generation 410: Best Fitness = 2906423.7583896248\n",
      "Generation 411: Best Fitness = 2918119.824642574\n",
      "Generation 412: Best Fitness = 2923704.8662620517\n",
      "Generation 413: Best Fitness = 2943377.097989524\n",
      "Generation 414: Best Fitness = 2957093.665923721\n",
      "Generation 415: Best Fitness = 2969273.0713265096\n",
      "Generation 416: Best Fitness = 2986956.8429159047\n",
      "Generation 417: Best Fitness = 2994499.0715936655\n",
      "Generation 418: Best Fitness = 3018752.1540221004\n",
      "Generation 419: Best Fitness = 3029558.425560934\n",
      "Generation 420: Best Fitness = 3042942.6715415986\n",
      "Generation 421: Best Fitness = 3052111.1887748437\n",
      "Generation 422: Best Fitness = 3056647.29883618\n",
      "Generation 423: Best Fitness = 3071131.0029736855\n",
      "Generation 424: Best Fitness = 3088479.5408054334\n",
      "Generation 425: Best Fitness = 3100596.385428173\n",
      "Generation 426: Best Fitness = 3111279.1232334278\n",
      "Generation 427: Best Fitness = 3116708.841754854\n",
      "Generation 428: Best Fitness = 3132184.534226905\n",
      "Generation 429: Best Fitness = 3135573.7780091735\n",
      "Generation 430: Best Fitness = 3147734.405049934\n",
      "Generation 431: Best Fitness = 3149013.586634672\n",
      "Generation 432: Best Fitness = 3173952.8007429866\n",
      "Generation 433: Best Fitness = 3173232.4439978506\n",
      "Generation 434: Best Fitness = 3185470.395082584\n",
      "Generation 435: Best Fitness = 3198813.957109841\n",
      "Generation 436: Best Fitness = 3213157.9428270156\n",
      "Generation 437: Best Fitness = 3232312.6804279676\n",
      "Generation 438: Best Fitness = 3237277.1759079727\n",
      "Generation 439: Best Fitness = 3248589.666734917\n",
      "Generation 440: Best Fitness = 3274322.1773324213\n",
      "Generation 441: Best Fitness = 3293665.007871336\n",
      "Generation 442: Best Fitness = 3300462.4856870044\n",
      "Generation 443: Best Fitness = 3303064.125670019\n",
      "Generation 444: Best Fitness = 3313054.710998397\n",
      "Generation 445: Best Fitness = 3320126.631016441\n",
      "Generation 446: Best Fitness = 3343713.5973177445\n",
      "Generation 447: Best Fitness = 3352361.9611162795\n",
      "Generation 448: Best Fitness = 3364589.3293049135\n",
      "Generation 449: Best Fitness = 3376118.1087554563\n",
      "Generation 450: Best Fitness = 3394323.7332946225\n",
      "Generation 451: Best Fitness = 3416787.619285835\n",
      "Generation 452: Best Fitness = 3420320.62865031\n",
      "Generation 453: Best Fitness = 3419410.2021989436\n",
      "Generation 454: Best Fitness = 3422469.8409755994\n",
      "Generation 455: Best Fitness = 3442904.6560317823\n",
      "Generation 456: Best Fitness = 3442257.7716977866\n",
      "Generation 457: Best Fitness = 3456389.800024174\n",
      "Generation 458: Best Fitness = 3464921.5244129854\n",
      "Generation 459: Best Fitness = 3489809.712213344\n",
      "Generation 460: Best Fitness = 3488659.246674987\n",
      "Generation 461: Best Fitness = 3499542.33417126\n",
      "Generation 462: Best Fitness = 3538894.155800192\n",
      "Generation 463: Best Fitness = 3542878.6795779476\n",
      "Generation 464: Best Fitness = 3548143.788131895\n",
      "Generation 465: Best Fitness = 3556444.1246148\n",
      "Generation 466: Best Fitness = 3595873.2575437115\n",
      "Generation 467: Best Fitness = 3615323.5831368454\n",
      "Generation 468: Best Fitness = 3614046.207782213\n",
      "Generation 469: Best Fitness = 3632604.2040705467\n",
      "Generation 470: Best Fitness = 3639944.260543535\n",
      "Generation 471: Best Fitness = 3648243.8335033143\n",
      "Generation 472: Best Fitness = 3653726.9385150834\n",
      "Generation 473: Best Fitness = 3669636.5374071784\n",
      "Generation 474: Best Fitness = 3678929.4167102\n",
      "Generation 475: Best Fitness = 3692902.0009300285\n",
      "Generation 476: Best Fitness = 3723284.759599533\n",
      "Generation 477: Best Fitness = 3729387.585011479\n",
      "Generation 478: Best Fitness = 3747825.400064716\n",
      "Generation 479: Best Fitness = 3747023.1574167223\n",
      "Generation 480: Best Fitness = 3751454.455335469\n",
      "Generation 481: Best Fitness = 3783039.5999422697\n",
      "Generation 482: Best Fitness = 3796284.906875502\n",
      "Generation 483: Best Fitness = 3809936.4067852735\n",
      "Generation 484: Best Fitness = 3828272.0004625753\n",
      "Generation 485: Best Fitness = 3864729.995726001\n",
      "Generation 486: Best Fitness = 3868865.7970684334\n",
      "Generation 487: Best Fitness = 3867709.0645241872\n",
      "Generation 488: Best Fitness = 3890656.440694334\n",
      "Generation 489: Best Fitness = 3918663.9397119987\n",
      "Generation 490: Best Fitness = 3918336.1247585523\n",
      "Generation 491: Best Fitness = 3936126.213111605\n",
      "Generation 492: Best Fitness = 3943316.3728025495\n",
      "Generation 493: Best Fitness = 3962904.7113647806\n",
      "Generation 494: Best Fitness = 3976816.389910118\n",
      "Generation 495: Best Fitness = 3995483.551022302\n",
      "Generation 496: Best Fitness = 4002265.906477411\n",
      "Generation 497: Best Fitness = 4010992.4894496775\n",
      "Generation 498: Best Fitness = 4040405.416083449\n",
      "Generation 499: Best Fitness = 4055862.1328436644\n",
      "Generation 500: Best Fitness = 4065252.462358489\n",
      "Generation 501: Best Fitness = 4104274.749642573\n",
      "Generation 502: Best Fitness = 4137568.7552612587\n",
      "Generation 503: Best Fitness = 4139384.909089435\n",
      "Generation 504: Best Fitness = 4150812.916863298\n",
      "Generation 505: Best Fitness = 4154234.071024841\n",
      "Generation 506: Best Fitness = 4179122.4992582733\n",
      "Generation 507: Best Fitness = 4186252.6622036034\n",
      "Generation 508: Best Fitness = 4211940.054841526\n",
      "Generation 509: Best Fitness = 4233743.312853515\n",
      "Generation 510: Best Fitness = 4241925.330936166\n",
      "Generation 511: Best Fitness = 4247118.824312933\n",
      "Generation 512: Best Fitness = 4265637.555147342\n",
      "Generation 513: Best Fitness = 4288894.456298008\n",
      "Generation 514: Best Fitness = 4296867.713338805\n",
      "Generation 515: Best Fitness = 4301587.487843202\n",
      "Generation 516: Best Fitness = 4314588.406855596\n",
      "Generation 517: Best Fitness = 4320872.239619585\n",
      "Generation 518: Best Fitness = 4338034.902864753\n",
      "Generation 519: Best Fitness = 4347422.925778351\n",
      "Generation 520: Best Fitness = 4362831.043898538\n",
      "Generation 521: Best Fitness = 4365586.364436555\n",
      "Generation 522: Best Fitness = 4377547.198945042\n",
      "Generation 523: Best Fitness = 4397032.693555592\n",
      "Generation 524: Best Fitness = 4430144.248431114\n",
      "Generation 525: Best Fitness = 4429484.794639867\n",
      "Generation 526: Best Fitness = 4453966.513285532\n",
      "Generation 527: Best Fitness = 4470881.4438719535\n",
      "Generation 528: Best Fitness = 4491345.623122072\n",
      "Generation 529: Best Fitness = 4498342.22454924\n",
      "Generation 530: Best Fitness = 4519932.247851019\n",
      "Generation 531: Best Fitness = 4528701.314601398\n",
      "Generation 532: Best Fitness = 4556916.436315529\n",
      "Generation 533: Best Fitness = 4572829.1092615165\n",
      "Generation 534: Best Fitness = 4611243.71994217\n",
      "Generation 535: Best Fitness = 4613703.26003695\n",
      "Generation 536: Best Fitness = 4649491.8682655655\n",
      "Generation 537: Best Fitness = 4648319.599435454\n",
      "Generation 538: Best Fitness = 4655564.142276702\n",
      "Generation 539: Best Fitness = 4673076.833789733\n",
      "Generation 540: Best Fitness = 4700953.477881073\n",
      "Generation 541: Best Fitness = 4704510.2715422725\n",
      "Generation 542: Best Fitness = 4712186.090662438\n",
      "Generation 543: Best Fitness = 4734616.546007102\n",
      "Generation 544: Best Fitness = 4738529.49697983\n",
      "Generation 545: Best Fitness = 4761770.465189803\n",
      "Generation 546: Best Fitness = 4766102.418366693\n",
      "Generation 547: Best Fitness = 4778155.097896737\n",
      "Generation 548: Best Fitness = 4790976.904650439\n",
      "Generation 549: Best Fitness = 4816782.42700005\n",
      "Generation 550: Best Fitness = 4816283.130348996\n",
      "Generation 551: Best Fitness = 4832547.158490844\n",
      "Generation 552: Best Fitness = 4837062.2927388\n",
      "Generation 553: Best Fitness = 4859618.2773273075\n",
      "Generation 554: Best Fitness = 4867408.936114742\n",
      "Generation 555: Best Fitness = 4877384.938660868\n",
      "Generation 556: Best Fitness = 4889095.069707419\n",
      "Generation 557: Best Fitness = 4911999.470560634\n",
      "Generation 558: Best Fitness = 4927682.346066875\n",
      "Generation 559: Best Fitness = 4941675.483424172\n",
      "Generation 560: Best Fitness = 4975233.310485847\n",
      "Generation 561: Best Fitness = 4975204.532503303\n",
      "Generation 562: Best Fitness = 4982986.876273581\n",
      "Generation 563: Best Fitness = 4998665.714762026\n",
      "Generation 564: Best Fitness = 5022194.007948388\n",
      "Generation 565: Best Fitness = 5026618.670917616\n",
      "Generation 566: Best Fitness = 5047690.446530135\n",
      "Generation 567: Best Fitness = 5073277.639860322\n",
      "Generation 568: Best Fitness = 5087414.705300895\n",
      "Generation 569: Best Fitness = 5093111.763239051\n",
      "Generation 570: Best Fitness = 5119724.40190624\n",
      "Generation 571: Best Fitness = 5134519.857159925\n",
      "Generation 572: Best Fitness = 5156908.203560774\n",
      "Generation 573: Best Fitness = 5167665.835933238\n",
      "Generation 574: Best Fitness = 5196937.169885907\n",
      "Generation 575: Best Fitness = 5215466.837178782\n",
      "Generation 576: Best Fitness = 5213086.7688353555\n",
      "Generation 577: Best Fitness = 5214748.54812752\n",
      "Generation 578: Best Fitness = 5258196.010890209\n",
      "Generation 579: Best Fitness = 5298340.934406987\n",
      "Generation 580: Best Fitness = 5297516.824775492\n",
      "Generation 581: Best Fitness = 5303696.529877754\n",
      "Generation 582: Best Fitness = 5313661.04033586\n",
      "Generation 583: Best Fitness = 5337423.466329867\n",
      "Generation 584: Best Fitness = 5346246.093010959\n",
      "Generation 585: Best Fitness = 5347545.770086626\n",
      "Generation 586: Best Fitness = 5378648.002290511\n",
      "Generation 587: Best Fitness = 5382206.782025841\n",
      "Generation 588: Best Fitness = 5391592.111015272\n",
      "Generation 589: Best Fitness = 5398389.712792181\n",
      "Generation 590: Best Fitness = 5407922.379173554\n",
      "Generation 591: Best Fitness = 5427163.647943936\n",
      "Generation 592: Best Fitness = 5439725.409518771\n",
      "Generation 593: Best Fitness = 5448206.51294215\n",
      "Generation 594: Best Fitness = 5463813.801051619\n",
      "Generation 595: Best Fitness = 5486105.642368187\n",
      "Generation 596: Best Fitness = 5500135.441877178\n",
      "Generation 597: Best Fitness = 5514946.255698856\n",
      "Generation 598: Best Fitness = 5552496.065132321\n",
      "Generation 599: Best Fitness = 5552379.592809928\n",
      "Generation 600: Best Fitness = 5553280.809597141\n",
      "Generation 601: Best Fitness = 5565855.280796122\n",
      "Generation 602: Best Fitness = 5598443.545835206\n",
      "Generation 603: Best Fitness = 5605294.589977624\n",
      "Generation 604: Best Fitness = 5638209.296959146\n",
      "Generation 605: Best Fitness = 5640050.819746059\n",
      "Generation 606: Best Fitness = 5658693.011946273\n",
      "Generation 607: Best Fitness = 5672649.159411886\n",
      "Generation 608: Best Fitness = 5696613.784278656\n",
      "Generation 609: Best Fitness = 5720855.716193487\n",
      "Generation 610: Best Fitness = 5741617.768179846\n",
      "Generation 611: Best Fitness = 5769666.553031048\n",
      "Generation 612: Best Fitness = 5790315.647595638\n",
      "Generation 613: Best Fitness = 5801428.668560553\n",
      "Generation 614: Best Fitness = 5819104.866836908\n",
      "Generation 615: Best Fitness = 5846690.359552676\n",
      "Generation 616: Best Fitness = 5866719.320294423\n",
      "Generation 617: Best Fitness = 5872730.911983549\n",
      "Generation 618: Best Fitness = 5895394.488390713\n",
      "Generation 619: Best Fitness = 5915650.828183892\n",
      "Generation 620: Best Fitness = 5938353.988885361\n",
      "Generation 621: Best Fitness = 5958080.848271419\n",
      "Generation 622: Best Fitness = 5968330.182088937\n",
      "Generation 623: Best Fitness = 5978292.955352096\n",
      "Generation 624: Best Fitness = 6015000.321459612\n",
      "Generation 625: Best Fitness = 6026955.276291658\n",
      "Generation 626: Best Fitness = 6040272.265645226\n",
      "Generation 627: Best Fitness = 6047247.676115747\n",
      "Generation 628: Best Fitness = 6086662.357590957\n",
      "Generation 629: Best Fitness = 6106311.549108784\n",
      "Generation 630: Best Fitness = 6118865.530589157\n",
      "Generation 631: Best Fitness = 6142742.194906976\n",
      "Generation 632: Best Fitness = 6162499.772744094\n",
      "Generation 633: Best Fitness = 6175341.465747772\n",
      "Generation 634: Best Fitness = 6174549.673657846\n",
      "Generation 635: Best Fitness = 6192750.820609993\n",
      "Generation 636: Best Fitness = 6228017.937721061\n",
      "Generation 637: Best Fitness = 6236006.676846552\n",
      "Generation 638: Best Fitness = 6271965.042368317\n",
      "Generation 639: Best Fitness = 6285356.173450989\n",
      "Generation 640: Best Fitness = 6292222.914405729\n",
      "Generation 641: Best Fitness = 6308508.848882497\n",
      "Generation 642: Best Fitness = 6320310.652911047\n",
      "Generation 643: Best Fitness = 6354006.608226892\n",
      "Generation 644: Best Fitness = 6366570.998090638\n",
      "Generation 645: Best Fitness = 6365343.577293478\n",
      "Generation 646: Best Fitness = 6387608.223596093\n",
      "Generation 647: Best Fitness = 6440521.358544889\n",
      "Generation 648: Best Fitness = 6438438.953403775\n",
      "Generation 649: Best Fitness = 6446250.5952145215\n",
      "Generation 650: Best Fitness = 6473518.3071509395\n",
      "Generation 651: Best Fitness = 6496633.612261558\n",
      "Generation 652: Best Fitness = 6534686.055255035\n",
      "Generation 653: Best Fitness = 6534514.099753758\n",
      "Generation 654: Best Fitness = 6534514.099753758\n",
      "Generation 655: Best Fitness = 6546732.772750407\n",
      "Generation 656: Best Fitness = 6573587.62632997\n",
      "Generation 657: Best Fitness = 6605452.8280713875\n",
      "Generation 658: Best Fitness = 6604022.32595144\n",
      "Generation 659: Best Fitness = 6665402.7636434315\n",
      "Generation 660: Best Fitness = 6681372.708637626\n",
      "Generation 661: Best Fitness = 6704211.632092449\n",
      "Generation 662: Best Fitness = 6739934.23592456\n",
      "Generation 663: Best Fitness = 6765600.11099631\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ale/repo/al912_project/test.ipynb Cell 2\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m ga_instance \u001b[39m=\u001b[39m pygad\u001b[39m.\u001b[39mGA(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     num_generations\u001b[39m=\u001b[39mnum_generations,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     num_parents_mating\u001b[39m=\u001b[39mnum_parents_mating,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     ),  \u001b[39m# Ensure initial population in [0,1]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39m# Running the GA\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m ga_instance\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39m# Best solution\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m solution, solution_fitness, solution_idx \u001b[39m=\u001b[39m ga_instance\u001b[39m.\u001b[39mbest_solution()\n",
      "File \u001b[0;32m~/anaconda3/envs/general/lib/python3.11/site-packages/pygad/pygad.py:2116\u001b[0m, in \u001b[0;36mGA.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2114\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprevious_generation_fitness \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_generation_fitness\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m   2115\u001b[0m \u001b[39m# Measuring the fitness of each chromosome in the population. Save the fitness in the last_generation_fitness attribute.\u001b[39;00m\n\u001b[0;32m-> 2116\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_generation_fitness \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcal_pop_fitness()\n\u001b[1;32m   2118\u001b[0m best_solution, best_solution_fitness, best_match_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_solution(\n\u001b[1;32m   2119\u001b[0m     pop_fitness\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_generation_fitness)\n\u001b[1;32m   2121\u001b[0m \u001b[39m# Appending the best solution in the current generation to the best_solutions list.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/general/lib/python3.11/site-packages/pygad/pygad.py:1688\u001b[0m, in \u001b[0;36mGA.cal_pop_fitness\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1686\u001b[0m     \u001b[39m# Check if batch processing is used. If not, then calculate this missing fitness value.\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness_batch_size \u001b[39min\u001b[39;00m [\u001b[39m1\u001b[39m, \u001b[39mNone\u001b[39;00m]:\n\u001b[0;32m-> 1688\u001b[0m         fitness \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitness_func(\u001b[39mself\u001b[39;49m, sol, sol_idx)\n\u001b[1;32m   1689\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(fitness) \u001b[39min\u001b[39;00m GA\u001b[39m.\u001b[39msupported_int_float_types:\n\u001b[1;32m   1690\u001b[0m             \u001b[39m# The fitness function returns a single numeric value.\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m             \u001b[39m# This is a single-objective optimization problem.\u001b[39;00m\n\u001b[1;32m   1692\u001b[0m             \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;32m/Users/ale/repo/al912_project/test.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m W \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moutput/sparse_v_W/W_case\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m.npy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m v \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moutput/sparse_v_W/v_case\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m.npy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m fitness_func \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m ga_instance, solution, solution_idx: fit_func(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     W, v, ga_instance, solution, solution_idx\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# GA parameters\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m num_iterations \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m  \u001b[39m# Set the number of iterations # 60000\u001b[39;00m\n",
      "\u001b[1;32m/Users/ale/repo/al912_project/test.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# print(f\"Lambda: {lambda_}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(solution)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m term1 \u001b[39m=\u001b[39m lambda_ \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mdot(x\u001b[39m.\u001b[39mT, np\u001b[39m.\u001b[39;49mdot(W, x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m term2 \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m lambda_) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mdot(v\u001b[39m.\u001b[39mT, x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ale/repo/al912_project/test.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m loss \u001b[39m=\u001b[39m term1 \u001b[39m+\u001b[39m term2\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygad\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# Define the objective function\n",
    "def fit_func(W, v, ga_instance, solution, solution_idx):\n",
    "    ###!! Calculating lambda, this method is only valid when no PPI is considered\n",
    "\n",
    "    mean_v = np.mean(v)\n",
    "    sd_v = np.std(v)\n",
    "\n",
    "    # for W, calculate row mean\n",
    "    mean_W = np.mean(W)\n",
    "    sd_W = np.std(W)\n",
    "    M_v = mean_v / sd_v\n",
    "    M_w = mean_W / sd_W\n",
    "    lambda_ = M_w / (M_v + M_w)\n",
    "    # print(f\"Lambda: {lambda_}\")\n",
    "\n",
    "    x = np.array(solution)\n",
    "\n",
    "    term1 = lambda_ * np.dot(x.T, np.dot(W, x))\n",
    "    term2 = (1 - lambda_) * np.dot(v.T, x)\n",
    "    loss = term1 + term2\n",
    "    return loss\n",
    "\n",
    "\n",
    "def on_generation(ga_instance):\n",
    "    for sol_idx, solution in enumerate(ga_instance.population):\n",
    "        # Ensure non-negativity\n",
    "        solution = np.maximum(solution, 0)\n",
    "        # solution = solution / np.sum(solution)\n",
    "        ga_instance.population[sol_idx] = solution\n",
    "    print(\n",
    "        f\"Generation {ga_instance.generations_completed}: Best Fitness = {ga_instance.best_solution()[1]}\"\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for idx in range(1, 5):\n",
    "        W = np.load(f\"output/sparse_v_W/W_case{idx}.npy\")\n",
    "        v = np.load(f\"output/sparse_v_W/v_case{idx}.npy\")\n",
    "        fitness_func = lambda ga_instance, solution, solution_idx: fit_func(\n",
    "            W, v, ga_instance, solution, solution_idx\n",
    "        )\n",
    "\n",
    "        # GA parameters\n",
    "        num_iterations = 10000  # Set the number of iterations # 60000\n",
    "        num_generations = (\n",
    "            num_iterations  # Assuming one generation per iteration\n",
    "        )\n",
    "        num_parents_mating = 10\n",
    "        sol_per_pop = 20\n",
    "        num_genes = len(W)  # Ensure num_genes matches the dimension of W and v\n",
    "        mutation_rate = 1 / (num_genes + 1)  # Set mutation rate\n",
    "        crossover_rate = 0.5  # Set crossover rate\n",
    "\n",
    "        # Creating an instance of the GA\n",
    "        ga_instance = pygad.GA(\n",
    "            num_generations=num_generations,\n",
    "            num_parents_mating=num_parents_mating,\n",
    "            fitness_func=fitness_func,\n",
    "            sol_per_pop=sol_per_pop,\n",
    "            num_genes=num_genes,\n",
    "            mutation_type=\"random\",\n",
    "            mutation_percent_genes=20,  # pygad uses percentage\n",
    "            crossover_type=\"single_point\",  # Experiment with different crossover methods\n",
    "            crossover_probability=crossover_rate,  # Set crossover rate\n",
    "            on_generation=on_generation,\n",
    "            stop_criteria=[\n",
    "                \"saturate_10\"\n",
    "            ],  # Stop if no improvement for 100 generations\n",
    "            keep_parents=1,\n",
    "            initial_population=np.random.uniform(\n",
    "                low=0.0, high=1.0, size=(sol_per_pop, num_genes)\n",
    "            ),  # Ensure initial population in [0,1]\n",
    "        )\n",
    "        # Running the GA\n",
    "        ga_instance.run()\n",
    "\n",
    "        # Best solution\n",
    "        solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "        print(\"Best Solution: \", solution)\n",
    "        print(\"Best Solution Fitness: \", solution_fitness)\n",
    "\n",
    "        # Save the best solution\n",
    "        # np.save(f\"output/best_solution_case{idx}.npy\", solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W is not symmetric.\n",
      "[[2.36792e-17 1.25733e+01 4.58668e-01 4.62585e-01 5.45183e-01]\n",
      " [3.35846e+00 2.39439e-16 3.35663e+00 3.35580e+00 3.35369e+00]\n",
      " [1.55892e-01 9.18533e+00 1.80846e-18 1.52127e-01 1.29038e-01]\n",
      " [1.31500e-01 1.11469e+01 1.25391e-01 1.18172e-16 1.68509e-01]\n",
      " [6.64737e-02 1.69014e+00 5.20587e-02 5.60532e-02 9.82460e-18]]\n",
      "=============\n",
      "[[2.36792e-17 3.35846e+00 1.55892e-01 ... 4.52723e-02 3.09185e-01\n",
      "  0.00000e+00]\n",
      " [1.25733e+01 2.39439e-16 9.18533e+00 ... 1.94375e+01 2.11762e+01\n",
      "  0.00000e+00]\n",
      " [4.58668e-01 3.35663e+00 1.80846e-18 ... 5.87584e-02 4.12739e-01\n",
      "  0.00000e+00]\n",
      " ...\n",
      " [4.54572e-01 3.35550e+00 1.61108e-01 ... 1.83586e-17 3.88158e-01\n",
      "  0.00000e+00]\n",
      " [3.88630e-01 3.35938e+00 1.98867e-01 ... 6.68339e-02 1.54275e-17\n",
      "  0.00000e+00]\n",
      " [7.63562e-01 3.33906e+00 1.68955e-01 ... 2.22946e-01 3.24079e-01\n",
      "  0.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load your W matrix\n",
    "W = np.load(\"output/v_W/W_case2.npy\")\n",
    "\n",
    "rtol = 1e-02  # relative tolerance\n",
    "atol = 1e-03  \n",
    "\n",
    "if np.allclose(W, W.T, rtol=rtol, atol=atol):\n",
    "    print(\"W is symmetric.\")\n",
    "\n",
    "else:\n",
    "    print(\"W is not symmetric.\")\n",
    "\n",
    "#print to 3 s.f.\n",
    "np.set_printoptions(precision=5)\n",
    "print(W[:5, :5])\n",
    "print(\"=============\")\n",
    "print(W.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to simulated_data.csv\n",
      "(5, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the parameters\n",
    "    num_genes = 10  # Number of variables (genes)\n",
    "    num_samples = 5  # Number of samples\n",
    "    data_range = (-0.5, 0.5)\n",
    "\n",
    "    k = 0.6\n",
    "    r = 0.65\n",
    "\n",
    "    # Generate means from a uniform distribution\n",
    "    means = np.random.uniform(\n",
    "        low=data_range[0], high=data_range[1], size=num_genes\n",
    "    )\n",
    "    # Generate the standard deviation matrix\n",
    "    std_dev = np.zeros((num_genes, num_genes))\n",
    "    np.fill_diagonal(\n",
    "        std_dev,\n",
    "        np.random.uniform(low=0.01, high=data_range[1], size=num_genes),\n",
    "    )\n",
    "\n",
    "    # Initialize the correlation matrix\n",
    "    corr_matrix = np.eye(num_genes)  # with zeros\n",
    "\n",
    "    # Define the significant genes\n",
    "    l = np.random.choice(\n",
    "        range(num_genes), size=int(0.2 * num_genes), replace=False\n",
    "    )\n",
    "\n",
    "    # Generate the modified means and correlations for significant genes\n",
    "    for i in l:\n",
    "        means[i] += k\n",
    "        for j in l:\n",
    "            if i != j:\n",
    "                corr_matrix[i, j] += r\n",
    "\n",
    "    # cov matrix is corr matrix_ih * std_i * std_h\n",
    "    cov_matrix = std_dev.dot(corr_matrix).dot(std_dev)\n",
    "\n",
    "    # Generate the simulated expression data\n",
    "    simulated_data = multivariate_normal.rvs(\n",
    "        mean=means, cov=cov_matrix, size=num_samples\n",
    "    )\n",
    "\n",
    "    # Convert the numpy array to a pandas DataFrame\n",
    "    df = pd.DataFrame(simulated_data)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(\"simulated_data_test.csv\", index=False)\n",
    "\n",
    "    print(\"Data saved to simulated_data.csv\")\n",
    "\n",
    "    print(simulated_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means [ 0.36124791 -0.12239389  1.0872388   0.24336767 -0.18461028  0.38343517\n",
      " -0.10862884  0.12641376  0.11064644  0.16519982]\n",
      "corr_matrix [[1.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   1.   0.   0.   0.   0.   0.   0.65 0.  ]\n",
      " [0.   0.   0.   1.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   1.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   1.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   1.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   1.   0.   0.  ]\n",
      " [0.   0.   0.65 0.   0.   0.   0.   0.   1.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  ]]\n",
      "cov_matrix [[0.08631339 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.23201425 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.053856   0.         0.         0.\n",
      "  0.         0.         0.01432101 0.        ]\n",
      " [0.         0.         0.         0.11339392 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.14283635 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.04942258\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.08826985 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05343993 0.         0.        ]\n",
      " [0.         0.         0.01432101 0.         0.         0.\n",
      "  0.         0.         0.00901335 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00854193]]\n"
     ]
    }
   ],
   "source": [
    "print(\"means\", means)\n",
    "print(\"corr_matrix\", corr_matrix)\n",
    "print(\"cov_matrix\", cov_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
